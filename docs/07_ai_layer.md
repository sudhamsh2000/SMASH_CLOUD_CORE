# AI Layer (Phase 2)

- Option: Ollama or local LLM runtime
- Integrations with Nextcloud apps or webhooks
- Resource monitoring and scheduling
